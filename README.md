# ğŸ’ Glamira Automated Data Pipeline Project (41.4M Records)

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng má»™t há»‡ thá»‘ng **Automated Data Pipeline** quy mÃ´ lá»›n Ä‘á»ƒ xá»­ lÃ½ dá»¯ liá»‡u hÃ nh vi ngÆ°á»i dÃ¹ng (User Behavioral Data) cá»§a Glamira. Há»‡ thá»‘ng tá»± Ä‘á»™ng hÃ³a luá»“ng dá»¯ liá»‡u tá»« MongoDB (On-premise VM) lÃªn Google BigQuery (Cloud Warehouse), Ä‘áº£m báº£o tÃ­nh toÃ n váº¹n vÃ  kháº£ nÄƒng truy váº¥n hiá»‡u suáº¥t cao.

## ğŸ— System Architecture

Há»‡ thá»‘ng Ä‘Æ°á»£c thiáº¿t káº¿ theo kiáº¿n trÃºc **Medallion Architecture (Bronze Layer)**:

1.  **Extraction**: Python script (`export_parallel.py`) sá»­ dá»¥ng ká»¹ thuáº­t xá»­ lÃ½ song song (Multi-processing) vÃ  Ä‘á»‹nh dáº¡ng **Parquet** (Snappy compression) Ä‘á»ƒ tá»‘i Æ°u hÃ³a viá»‡c trÃ­ch xuáº¥t 41.4M báº£n ghi tá»« MongoDB.
2.  **Staging**: Dá»¯ liá»‡u Ä‘Æ°á»£c Ä‘áº©y lÃªn **Google Cloud Storage (GCS)** lÃ m vÃ¹ng Ä‘á»‡m.
3.  **Automation**: **Cloud Function (Gen 2)** tá»± Ä‘á»™ng kÃ­ch hoáº¡t qua Eventarc Ä‘á»ƒ náº¡p dá»¯ liá»‡u vÃ o BigQuery ngay khi cÃ³ file má»›i táº£i lÃªn bucket.
4.  **Storage**: Tá»• chá»©c dá»¯ liá»‡u vÃ o 2 Dataset (`glamira_bronze` vÃ  `glamira_project6`) trÃªn **BigQuery**.



---

## ğŸ“Š Data Inventory & Schema (Requirement 3)

Há»‡ thá»‘ng quáº£n lÃ½ 3 nguá»“n dá»¯ liá»‡u Ä‘a Ä‘á»‹nh dáº¡ng, tá»•ng há»£p thÃ nh 5 báº£ng chiáº¿n lÆ°á»£c:

### 1. Dataset: `glamira_bronze`
* **`summary_raw`**: Dá»¯ liá»‡u thÃ´ náº¡p tá»« 4 file Parquet (41.4 triá»‡u dÃ²ng).
* **`summary_final` (33 Fields)**: Dá»¯ liá»‡u hÃ nh vi Ä‘Ã£ Ä‘Æ°á»£c bÃ³c tÃ¡ch JSON. Chá»©a cÃ¡c nhÃ³m trÆ°á»ng:
    * *Identity*: `ip`, `device_id`, `email`.
    * *Behavior*: `event_type`, `key_search`, `current_url`.
    * *Commerce*: `price`, `currency`, `order_id`.
* **`ip_locations` (5 Fields)**: Báº£ng tra cá»©u Ä‘á»‹a lÃ½ (`country`, `region`, `city`) dá»±a trÃªn IP address.
* **`summary_with_locations`**: Báº£ng tá»•ng há»£p (Join) phá»¥c vá»¥ phÃ¢n tÃ­ch Reporting.

### 2. Dataset: `glamira_project6`
* **`products_raw` (28 Fields)**: 18,000 báº£n ghi thÃ´ng tin sáº£n pháº©m tá»« file **JSONL**.
    * *Jewelry Attributes*: `gold_weight`, `material_design`, `collection`, `price`.

---

## ğŸ” Data Profiling Results

QuÃ¡ trÃ¬nh "khÃ¡m sá»©c khá»e" dá»¯ liá»‡u (Profiling) xÃ¡c nháº­n:
* **Integrity**: Tá»· lá»‡ khá»›p IP giá»¯a `summary_final` vÃ  `ip_locations` Ä‘áº¡t má»©c tá»‘i Æ°u, há»— trá»£ phÃ¢n tÃ­ch báº£n Ä‘á»“ nhiá»‡t (Heatmap) chÃ­nh xÃ¡c.
* **Optimization**: Báº£ng lá»›n Ä‘Æ°á»£c cáº¥u hÃ¬nh **Partitioning** theo thá»i gian giÃºp giáº£m 90% chi phÃ­ truy váº¥n.
* Tá»•ng sá»‘ dÃ²ng Summary,"41,432,460"
* Tá»•ng sá»‘ dÃ²ng IP Locations,"3,239,628"
* Tá»•ng sá»‘ dÃ²ng Products,"35,296"
* Sá»‘ lÆ°á»£ng IP thiáº¿u,0 
* Tá»· lá»‡ khá»›p IP (Match Rate),100.0% 
* Sá»‘ lÆ°á»£ng Email thiáº¿u,"397"
* Sá»‘ loáº¡i tiá»n tá»‡,85

---

## ğŸ›  Tech Stack & Skills
* **Languages**: Python (Pandas, PyArrow, Pymongo), SQL (BigQuery Standard SQL).
* **GCP Services**: Compute Engine, Cloud Storage, Cloud Functions (Gen 2), BigQuery.
* **Data Formats**: Parquet, JSONL, CSV.
* **Techniques**: Parallel Processing, Data Flattening, Medallion Architecture.

## ğŸ“ Repository Structure
```text
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ export_parallel.py      # Extracting 41M rows with Parallelism
â”‚   â””â”€â”€ main.py                 # Cloud Function for Automated Ingestion
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ bigquery_schema.sql     # Full DDL for 5 tables
â”‚   â””â”€â”€ data_profiling.sql      # Quality check & Analysis queries
â”œâ”€â”€ screenshots/                # Evidence of successful GCP deployment
â””â”€â”€ Data_Profiling_Report.pdf   # Executive summary of data quality
